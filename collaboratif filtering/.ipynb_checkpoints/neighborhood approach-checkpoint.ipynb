{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "question_id": 1
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ff1b8714d809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Calcule de la sparsité\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msparsity\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_users\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics.pairwise as dist\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# sparsity\n",
    "sparsity= round(1.0 - len(df) / float(n_users * n_items),3)*100\n",
    "\n",
    "#Nombre d'utilisateurs et de contenu.\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "\n",
    "from sklearn import cross_validation as cv\n",
    "\n",
    "#Séparation des données en deux train_data et test_data.\n",
    "train_data, test_data = cv.train_test_split(df, test_size=0.25)\n",
    "train_data.head(5)\n",
    "\n",
    "#Création de deux matrices user-item train_data_matrix et test_data_matrix.\n",
    "train_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in train_data.itertuples():\n",
    "    train_data_matrix[line[1]-1, line[2]-1] = line[3]\n",
    "    \n",
    "test_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[1]-1, line[2]-1] = line[3]\n",
    "\n",
    "#Calcule de la matrice de similarité\n",
    "user_similarity = dist.cosine_similarity(train_data_matrix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########## \n",
    "\n",
    "def pred_user(ratings, user_similarity, k):\n",
    "    \n",
    "    pred = np.zeros(ratings.shape)\n",
    "    \n",
    "    for u in range(ratings.shape[0]):\n",
    "        \n",
    "        top_k_users = [np.argsort(user_similarity[:,u])[:-k-1:-1]]\n",
    "        \n",
    "        for i in range(ratings.shape[1]):\n",
    "            \n",
    "            pred[u, i] = user_similarity[u, :][top_k_users].dot(ratings[:, i][top_k_users]) \n",
    "            pred[u, i] /= np.sum(np.abs(user_similarity[u, :][top_k_users])) + 0.000001  #Pour éviter une division par zero \n",
    "            \n",
    "    return pred\n",
    "\n",
    "\n",
    "def pred_item(ratings, item_similarity, k):\n",
    "    \n",
    "    pred = np.zeros(ratings.shape)\n",
    "    \n",
    "    for i in range(ratings.shape[1]):\n",
    "        \n",
    "        top_k_items = [np.argsort(item_similarity[:,i])[:-k-1:-1]]\n",
    "        \n",
    "        for u in range(ratings.shape[0]):\n",
    "            \n",
    "            pred[u, i] = item_similarity[i, :][top_k_items].dot(ratings[u, :][top_k_items].T) \n",
    "            pred[u, i] /= np.sum(np.abs(item_similarity[i, :][top_k_items])) + 0.000001   #Pour éviter une division par zero \n",
    "                \n",
    "    return pred   \n",
    "\n",
    "\n",
    "def predict_topk(ratings, similarity, kind='user', k = 40):\n",
    "    \n",
    "    pred = np.zeros(ratings.shape)\n",
    "    \n",
    "    if kind == 'user':\n",
    "        \n",
    "        pred = pred_user(ratings, similarity, k)\n",
    "        \n",
    "    if kind == 'item':\n",
    "        \n",
    "        pred = pred_item(ratings, similarity, k)\n",
    "        \n",
    "    return pred  \n",
    "\n",
    "\n",
    "def get_rmse(pred, actual):\n",
    "    \n",
    "    \n",
    "    pred = pred[actual.nonzero()].flatten() # Ignore nonzero terms.\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return np.sqrt(mean_squared_error(pred, actual))\n",
    "\n",
    "###########\n",
    "\n",
    "\n",
    "Test et Affichage graphique\n",
    "\n",
    "# Test\n",
    "k_array = [5, 15, 30, 50, 100, 200]\n",
    "user_train_rmse = []\n",
    "user_test_rmse = []\n",
    "item_test_rmse = []\n",
    "item_train_rmse = []\n",
    "\n",
    "for k in k_array:\n",
    "    user_pred = predict_topk(train_data_matrix, user_similarity, kind='user', k=k)\n",
    "    item_pred = predict_topk(train_data_matrix, item_similarity, kind='item', k=k)\n",
    "    \n",
    "    user_train_rmse += [get_rmse(user_pred, train_data_matrix)]\n",
    "    user_test_rmse += [get_rmse(user_pred, test_data_matrix)]\n",
    "    \n",
    "    item_train_rmse += [get_rmse(item_pred, train_data_matrix)]\n",
    "    item_test_rmse += [get_rmse(item_pred, test_data_matrix)] \n",
    "    \n",
    "# Affichage\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "\n",
    "pal = sns.color_palette(\"Set1\", 4)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(k_array, user_train_rmse, c=pal[0], label='User-based train', alpha=0.5, linewidth=5)\n",
    "plt.plot(k_array, user_test_rmse, c=pal[1], label='User-based test', linewidth=5)\n",
    "plt.plot(k_array, item_train_rmse, c=pal[2], label='Item-based train', alpha=0.5, linewidth=5)\n",
    "plt.plot(k_array, item_test_rmse, c=pal[3], label='Item-based test', linewidth=5)\n",
    "plt.legend(loc='best', fontsize=20)\n",
    "plt.xticks(fontsize=16);\n",
    "plt.yticks(fontsize=16);\n",
    "plt.xlabel('k', fontsize=30);\n",
    "plt.ylabel('RMSE', fontsize=30);\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.8))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "DataScientest - Edit",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "n_questions": 1
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
